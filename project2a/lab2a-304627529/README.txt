Bradley Zhu - 304627529
Project 2A

lab2_add.c is a C program that implements and tests a shared variable add
function.

SortedList.h is a header file describing the interfaces for linked list
operations

SortedList.c is a C module tha impliments methods for a sorted doubly linked
list.

lab2_list.c is a C program that impliments specified options and produces
statisitics.

My Makefile can build (compiles all programs), tests (run test cases to
generate CSV files), graphs (uses gnuplot to create graphs), tarball (creates
deliverable tarbell), and clean (cleans output).

lab2_add.csv and lab2_list.csv are data files.

My various pictures are graphs generated by gnuplot.

My README.txt contains descriptions of files and answers to questions.

Question 2.1.1
	With a smaller number of iterations, because the overhead is very long,
	one thread could finish before another thread starts its calculations.
	Also, with a larger number of iterations, it increases the odds of a
	conflict.  With a significantly smaller number of iterations, it
	decreases the odds of a conflict.

Question 2.1.2
	Yield runs are so much slower because we are forcing the calling thread
	to yield the CPU.  This means we need to save the state of the thread
	before loading another.  This takes much more time than just a
	normal execution.
	We can't get valid per-operation timings with the yield option because
	our operations are being interrupted by yields.

Question 2.1.3
	The cost of creating new threads is expensive.  With increasing
	iterations, the cost of creating the new threads is smaller and a
	smaller percentage of the time, causing the average cost per
	operation to drop.  To know how many iterations to run, we could either
	just use a very large number of iterations so cost per operation
	will be similar to real time.  Or we could start the thread first,
	initialize the timer, use mutex for each thread and lock it, then unlock
	them all while starting all the timers.

Question 2.1.4
	When there is a low number of threads, the odds of a conflict are much
	lower as well, so the locking mechanisms don't need to be used as often.
	When there are more threads, the odds of a conflict are much higher.
	The locking mechanisms will be used more often, which will create
	overhead costs that take a while.
	When the thread is waiting for other threads, the CPU is still working.
	This makes it much more expensive when there are a lot of threads.

Question 2.2.1
	In both of them as the number of threads went up, the cost for operation
	also went up.  The reason for the difference in rate of growth is
	because the various linked list operations cost much more time than just
	adding, the locks can be held for a much longer time.  The probability
	of conflicts is much higher, so more threads will be blocked and there
	will be much more overhead.

Question 2.2.2
	Both my Mutex and my Spin locks go up with more threads.  They both
	do that because with more threads comes more collisions between them.
	They differ in actual cost slightly because they are different
	locking mechanisms.  Spin locks should be more costly on the CPU.
